---
id: introduction
title: Fellowship Assessment
sidebar_label: Fellowship Assessment
---
**Contact details**

Australian College of Rural and Remote Medicine<br />
Level 1, 324 Queen Street<br />
GPO Box 2507<br />
Brisbane QLD 4000<br />
P: (+61) 7 3105 8200 or 1800 223 226<br />
F: (+61) 7 3105 8299<br />
E: assessment@acrrm.org.au<br />
Website: [www.acrrm.org.au](www.acrrm.org.au)<br />
ABN: 12 078 081 848

**Copyright**

© 2021 Australian College of Rural and Remote Medicine. All rights reserved. No part of this document may be reproduced by any means or in any form without express permission in writing from the Australian College of Rural and Remote Medicine.

**Version 2.5.2023**

Date published: April 2023<br />
Date implemented: April 2023<br />
Date for review: December 2023<br />

*ACRRM acknowledges Australian Aboriginal People and Torres Strait Islander People as the first inhabitants of the nation.  We respect the traditional owners of lands across Australia in which our members and staff work and live and pay respect to their elders past present and future.*

#### The Australian College of Rural and Remote Medicine

# Introduction

### Philosophy of ACRRM Assessment

The Australian College of Rural and remote Medicine (College) views assessment as an
ongoing and integral part of learning. The assessment process has a purposeful developmental design, that assists learners in identifying and understanding their strengths and weaknesses and providing feedback for guidance of future development.  The assessment program is designed to contribute to the development of lifelong learning practices and skills.

The College has developed, and delivers, the assessment program based on three key principles:

* Candidates can participate in assessment within the locality where they live and work,
  avoiding depopulating rural and remote Australia of their medical workforce (candidates 
  and assessors) during assessments; 
* The content of assessments is developed by clinically active rural and remote medical
    practitioners; and
  *﻿ Assessment plays a role in enabling candidates to become competent, confident and safe medical practitioners practising independently in their provision of health care to rural and remote individuals and communities.

### Programmatic approach

The College assessment process is designed using a programmatic approach. The programmatic approach allows the College to combine assessment methods with different psychometric properties, i ncluding workplace based and standardised assessments. For example, there is a balance between the clinical assessment in Structured Assessment using Multiple Patient Scenarios (StAMPS), which provides a highly structured and standardised approach, and the Case Based Discussion (CBD), which provides an assessment of the candidate’s clinical practice in the unique setting of their own clincial environment. Similarly, the Multi-Source Feedback (MSF) and the formative Mini-Clinical Evaluation Exercise (miniCEX) measure different aspects of the candidate's professional behaviour, one as perceived by patients and colleagues and the other through direct assessor observation.

Each assessment item has proven validity and reliability while assessing different aspects of the candidate’s skills, knowledge, and attitudes from different perspectives. The combination of approaches provides a more nuanced and detailed picture of a registrar’s development. 

Each candidate is required to achieve a minimum of a pass grade in each of the summative assessment modalities. The combination of passing standard outcomes demonstrates that each candidate has requisite knowledge, skills and attitudes required for rural generalist practice as outlined in the ACRRM Rural Generalist Curriculum.

The combination of modalities ensures that each competency is assessed at least once during the training program. For example, professionalism is predominantly measured by the MSF assessment, while applied knowledge is predominantly measured by the Multi-Choice Question (MCQ) assessment. 

### Principles of Assessment

Miller (1990) introduced an important framework that can be presented as four tiers/levels of a pyramid to categorise the different levels at which trainees can be assessed throughout their training. Collectively, the College assessments embrace all four levels of Miller's Pyramid (Figure 1).

Miller emphasised that all four levels - knows, knows how, shows how and does – are required to be assessed to obtain a comprehensive understanding of a trainee’s ability. 

*Does*:		Performance integrated into practice   \
*S﻿hows how*:	Simulated demonstration of skills in an examination situation\
*K﻿nows how*:	Application of knowledge to medically relevant situations\
*K﻿nows*:		Knowledge or information that the candidate has learned

Examples of the assessment tools at each level of College assessments are:

**Does** (Action):				MSF, formative MiniCEX, Logbook & CBD\
**Shows How** (Performance):	StAMPS, formative MiniCEX, CBD\
**Knows How** (Competence):	StAMPS		\
**Knows** (Knowledge):		MCQs

![](/img/1.png)

*`Figure 1: Miller G 1990 The Assessment Clinical Skills/Competence/Performance`*

### Assessment blueprint

The assessment program has been developed around the [Rural Generalist Curriculum](https://www.acrrm.org.au/resources/training/curriculum) competencies under the eight domain of rural practice. 

**Domain 1 - Provide expert medical care in all rural contexts**

![](/img/domain-1.jpg)

**Domain 2 - Provide primary care**

![](/img/domain-2.jpg)

**Domain 3 - Provide secondary medical care**

![](/img/domain-3.jpg)

**Domain 4 - Respond to medical emergencies**

![](/img/domain-4.jpg)

**Domain 5 - Apply a population health approach**

![](/img/domain-5.jpg)

**Domain 6 - Work with Aboriginal, Torres Strait Islander and other culturally diverse communities to improve health and wellbeing**

![](/img/domain-6.jpg)

**Domain 7 - Practise medicine with an ethical, intellectual and professional framework**

![](/img/domain-7.jpg)

**Domain 8 - Provide safe medical care while working in geographic and professional isolation**

![](/img/domain-8.jpg)

### Examiners, Assessors and Item Writers

The College has a team of writers, editors and assessors. The College aims to include as broad as possible representation of geographic and demographic membership in the team. Core Generalist Training assessment team members are required to be experienced rural practitioners who hold FACRRM. Advanced Specialised Training assessment team members are comprised of a combination of doctors holding Fellowship of ACRRM (FACRRM) and Fellows of other relevant specialist medical colleges.

All College Assessors undergo training throughout their time in the role of Assessor. 

The “expert team” developing assessment items for MCQ and StAMPS has input from a larger group of practising rural doctors. 

The College uses several processes to evaluate the effectiveness of the Fellows who contribute to assessment modalities. Post-assessment feedback from candidates, assessors, invigilators and others involved in assessment is evaluated routinely after each assessment. This information is reviewed by the lead assessors and fed back to the assessors and/or writers as appropriate.

### Code of Conduct

T﻿he College has an Examiner Charter and Code of Conduct that outlines the examiner's roles and responsibilities. The Code of Conduct is available on the College website [here](chrome-extension://efaidnbmnnnibpcajpcglclefindmkaj/https://www.acrrm.org.au/docs/default-source/all-files/academic-code-of-conduct.pdf?sfvrsn=559890eb_20).

### Conflict of interest

E﻿xaminers are required to declare a conflict of interest with any candidate they are assigned to assess prior to the assessment taking place. A declared conflict of interest will be taken into consideration and addressed accordingly. In CBD registrars are made aware of who will be assessing them in advance and are able to notify the College of any conflict of interest.

### Quality assurance processes

A range of quality assurance processes are used by the College's assessment program.

The College has a documented process based on best practice for standard setting and definition of the cut-off point between a pass and fail in each of the summative assessment modalities. These are described in the chapters relating to each modality.

Following an assessment, standard question reliability statistics such as Cronbach’s alpha are considered, with reliable questions/items placed in the repository for future assessments or to be included in publicly released practice assessments. Those with poor reliability are redeveloped or retired. 

When StAMPS is delivered across multiple sites, the Assessors assessing the same scenario attend a moderator session together with the lead Assessor to facilitate consistent delivery and marking of the scenario. At each StAMPS assessment centre there is a lead Assessor to ensure that the assessment is delivered in a fair and consistent manner and that process has been adhered to. The lead Assessor will observe Assessors across the assessment session and replace the Assessor when a conflict of interest has been declared. The lead Assessor is also responsible for providing feedback to Assessors. At the conclusion of the StAMPS all Assessors attend a debriefing session which includes an opportunity for Assessors to calibrate their marking. 

As a standard part of College assessment processes, assessments may be recorded. Candidates are notified of when this is occurring and continued participation in the assessment is considered consent to the recording. These recordings are used for the purpose of quality assurance and are the property of the College. Recordings are not made available to candidates or medical educators. Retention of recordings is managed in line with the College's document management policy.

The College formally evaluates the validity and reliability of each assessment modality prior to finalising results. Formal statistical testing is completed after each MCQ and StAMPS assessment to identify any discrepancies that may suggest the assessment was unfair for all or some candidates. This analysis includes performance breakdown of each StAMPS scenario for each day as well as Examiner grading and candidate cohort analysis. The CBD assessment is formally analysed through regular year-round session reviews and statistical analysis at the end of each year.

The College conducts ongoing evaluation of the assessment process to ensure fairness and equity for all participants.  After each assessment, candidates, invigilators, examiners and staff are invited to provide feedback via an anonymous online survey. The College has introduced a continuous quality assurance process for all assessments which is reported to the Assessment Committee.

The results of these processes feed directly back to the Assessment team, informing policy and procedure and contribute to the ongoing development and refinement of all processes. This process also provides a formal route to inform the Training program about the educational impact of the assessment modalities. 

The Assessment Committee provides oversight of all aspects of the assessment process. This duly constituted Committee reports to the Education Council.

### Candidate assessment rules

The following rules apply to a:ll College assessments:

* Candidates must arrive at the approved venue at the time specified in the instructions to candidates that is provided prior to the assessment date.
* Candidates must provide valid photographic identification (e.g. driver’s licence or passport) to the invigilator for verification of identity.
* Food or drink is not permitted into the assessment room other than a clear plastic bottle of water or food required for medical reasons.
* Any items that have note been authorised by the College are not permitted to be taken into the assessment room by a candidate.
* Mobile phones and all other electronic devices, including but not limited to, smart watched and wireless communication devices must be turned off and left with the invigilator.
* Candidates are strictly prohibited from accessing any component and function of the computer, email or internet sites, other than the platform used for the conduct of the examination.
* Candidates must be accompanied by their invigilator or authorised person if a restroom break is required.
* At the end of the exam, candidates must leave all hand-written notes and exam material at the assessment venue
* Candidates must not share any information related to the content of the exam, this is a serious breach of the College’s [Academic Code of Conduct](https://www.acrrm.org.au/docs/default-source/all-files/academic-code-of-conduct.pdf?sfvrsn=559890eb_14) and will be dealt with accordingly.

### Venues and Invigilators

All candidates should refer to the relevant [Assessment Venue Requirements](https://www.acrrm.org.au/resources/assessment/handbooks-guides) when choosing an assessment and invigilator.

##### *Venue*

A candidate is required to undertake their assessments at a venue that has been approved by the Assessment team.

The venues in which a candidate can undertake assessments are outlined in the relevant [Assessment Venue Requirements](https://www.acrrm.org.au/resources/assessment/handbooks-guides) document available on the College website. It is the candidate’s responsibility to ensure that the minimum requirements as indicated in the documents below are met.

Assessments cannot be conducted in a private residence (with the exception of Mock StAMPS) and candidates must ensure that the room being used does not contain any reference material and all computers in the room must be turned off

##### *Invigilators*

Invigilators play a central role in ensuring the security of this examination is maintained at all times. Candidates are responsible for finding a suitable invigilator and will be unable to undertake the assessment without an appropriate invigilator. 

All invigilators are subject to approval by the Assessment team, who has the discretionary authority to approve or decline each nominated invigilator. If a nominated invigilator is deemed unsuitable for any reason, the candidate will be notified and required to nominate another invigilator. Invigilators are paid by the College. 

### Incidents or irregularities

A candidate or assessor who has a concern about the management or conduct of the assessment should complete an [Incident Report](https://www.acrrm.org.au/docs/default-source/all-files/examination-incident-report-form.pdf?sfvrsn=8a69d668_2). An Incident Report must be provided to the Assessment team within 48 hours of the conclusion of the assessment.

Examples of incidents or other irregularities include but not limited to:

* An uncooperative candidate or assessor
* Not following the assessment procedure 
* Disturbances (e.g. unexpected noisy consulting room)
* Disruptions (e.g. loss of power or telephone malfunction)

### Results

When all post assessment quality assurance processes are complete, a recommendation is presented to the ACRRM Board of Examiners (BoE).  The BoE meets on a regular basis to ratify results.  Candidates are provided with an outcome letter and feedback report (if applicable) shortly after the ratification of results by the BoE.

Once available, results are uploaded to the “My Documents” section of a candidate’s “My College” portal, accessible via the College website. Candidates will receive an email notification once results are uploaded. The dates for release of results are generally published for each assessment on the [Assessment, date and enrolments and fees](https://www.acrrm.org.au/fellowship/discover-fellowship/assessment/assessment-dates-enrolments) webpage.

### Public assessment reports

A report is published on the College website following each Core Generalist Training (CGT), Advanced Specialty Training (AST) Emergency Medicine (EM) StAMPS and MCQ assessment. CBD public reports are published annually. The public report provides assessment statistics, a description of the scenarios/questions, feedback from the Principal Assessor and a summary of stakeholder feedback and improvements planned. The [Assessment Public Reports](https://www.acrrm.org.au/resources/assessment/public-assessment-reports) are published on Assessment resources webpage. 

### Undertaking Assessments Overseas

The College has provisions in place for candidates who wish to undertake their assessment outside of Australia. Candidates who wish to undertake an assessment overseas must contact the Assessment team as soon as practicable for further advice before finalising enrolment.

The MCQ and StAMPS assessments can be completed overseas, subject to appropriate invigilation and technical requirements being met. See [Assessment Venue Requirements](https://www.acrrm.org.au/docs/default-source/all-files/examination-venue-requirements.pdf?sfvrsn=12530098_2) for further information. 

The MSF, CBD and formative miniCEX can only be undertaken overseas if in an approved overseas training placement. Refer to the [Overseas Training Placements policy](https://www.acrrm.org.au/docs/default-source/all-files/overseas-training-placements-policy.pdf?sfvrsn=26500726_6).