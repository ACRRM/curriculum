---
id: introduction
title: Fellowship Assessment
sidebar_label: Fellowship Assessment
---
### The Australian College of Rural and Remote Medicine

## Philosophical underpinnings

The Australian College of Rural and remote Medicine (College) views assessment as an
ongoing and integral part of learning. The process is developmental in nature, assists learners
in identifying and understanding their strengths and weaknesses and provides guidance for
additional development. It also enables candidates to become competent, confident and safe
medical practitioners practising independently in their provision of health care to the public.

The College has developed its assessment program based on two key principles:

- Candidates can participate in assessment within the locality where they live and work,
preventing depopulating rural and remote Australia of their medical workforce (candidates
and assessors) during assessment period; and
- The content of assessments is developed by clinically active rural and remote medical
practitioners.

## Programmatic approach

A feature of the College assessment process is the ‘programmatic approach’ i.e. assessment
is a ‘program’ across the entire four years of training, rather than a specific instrument or
assessment.

The programmatic approach allows the College to combine assessment methods with
different psychometric properties, as well as allowing for a combination of workplace based
and standardised assessments. For example, there is a balance between the clinical
assessment in Structured Assessment using Multiple Patient Scenarios (StAMPS), which
provides a highly structured and standardised approach, and the Case Based Discussion
(CBD), which provides an assessment of the candidate’s clinical practice in their own
environment. Each assessment has proven validity and reliability and each measures a
different aspect of the candidate’s skills and knowledge.

Similarly, the Multi-Source Feedback (MSF) and the formative Mini-Clinical Evaluation
Exercise (miniCEX) measure different attributes of the candidate’s professional behaviour,
one as perceived by patients and colleagues and the other through direct assessor
observation. As each modality measures different aspects of the candidate’s knowledge, skills
and attitudes and from a different perspective, the combination of approaches provides a more
nuanced and detailed picture.

Each candidate is required to achieve a minimum of a pass grade in each of the summative
assessment modalities, instead of simply totalling the scores and achieving an overall pass
score. This ensures that each candidate has the requisite knowledge, skills and attitudes as
expressed though the educational objectives of the training program.

The combination of modalities ensures that each competency is assessed at least once during
the training program, although each individual modality only measures competencies
appropriate to the modality of measurement. For example, professionalism is predominantly
measured by the MSF assessment, while applied knowledge is predominantly measured by
the Multi-Choice Question (MCQ) assessment.

## Principles of Assessment

Miller (1990) introduced an important framework that can be presented as four tiers/levels of
a pyramid to categorise the different levels at which trainees can be assessed throughout their
training.

Collectively, the College assessments embrace all four levels of Miller’s Pyramid (Figure 1).
Miller emphasised that all four levels - knows, knows how, shows how and does – are required
to be assessed to obtain a comprehensive understanding of a trainee’s ability. In other words,
that candidates are required to demonstrate that they ‘know’, that they ‘know how’, that they
can ‘show how’, and finally, what the candidate actually ‘does’ in the workplace. 
